{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "DATA_FILE = 'data/buenos-aires_argentina.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class XmlReader:\n",
    "    \"\"\"\n",
    "    XML parser using ElementTree object adding limit and filter options\n",
    "    See https://stackoverflow.com/a/42193997/3456290\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.cache = defaultdict(list)\n",
    "        self.root = None\n",
    "        \n",
    "    def reset_doc(self, filename):\n",
    "        self.doc = ET.iterparse(filename, events=('start', 'end'))\n",
    "        _, self.root = next(self.doc)\n",
    "\n",
    "    def root_tag(self):\n",
    "        if self.root is None:\n",
    "            self.reset_doc(self.filename)\n",
    "        return self.root.tag\n",
    "    \n",
    "    def count_tags(self, limit=None, filter_tag=None):\n",
    "        tags = defaultdict(int)\n",
    "        tags[self.root_tag()] = 1\n",
    "        for e in self.iterate(limit=limit, filter_tag=filter_tag):\n",
    "            tags[e.tag] += 1\n",
    "            for ee in e.getchildren():\n",
    "                tags[ee.tag] += 1\n",
    "        return tags\n",
    "    \n",
    "    def iterate(self, limit=None, filter_tag=None, use_cache=True):\n",
    "        \"\"\"\n",
    "        Parse XML file allowing to use limit and filter optimising performance\n",
    "        \n",
    "        Args:\n",
    "            limit(int): Limit of nodes to yield\n",
    "            filter_tag(string): Tag name to apply as a filte\n",
    "        \"\"\"\n",
    "        if use_cache and len(self.cache[(filter_tag, limit)]) > 0:\n",
    "            print('Using cache...')\n",
    "            for e in self.cache[(filter_tag, limit)]:\n",
    "                yield e\n",
    "            return True\n",
    "        if self.root is None:\n",
    "            self.reset_doc(self.filename)\n",
    "        count = 0\n",
    "        start_tag = None\n",
    "        for event, element in self.doc:\n",
    "            if limit is not None:\n",
    "                if count == limit:\n",
    "                    return True\n",
    "            if event == 'start' and start_tag is None:\n",
    "                if filter_tag is None or (filter_tag is not None and filter_tag == element.tag):\n",
    "                    start_tag = element.tag\n",
    "            if event == 'end' and element.tag == start_tag:\n",
    "                if use_cache:\n",
    "                    self.cache[(filter_tag, limit)].append(element)\n",
    "                yield element\n",
    "                count += 1\n",
    "                start_tag = None\n",
    "                self.root.clear()\n",
    "    \n",
    "data = XmlReader(DATA_FILE)\n",
    "#display(data.count_tags(filter_tag='node'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'member': 202263,\n",
       " 'nd': 2006656,\n",
       " 'node': 1553682,\n",
       " 'osm': 1,\n",
       " 'relation': 9559,\n",
       " 'tag': 1736778,\n",
       " 'way': 338006}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test()\n",
    "display(dict(data.count_tags()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyAuditor:\n",
    "    \n",
    "    def __init__(self, xml_reader):\n",
    "        self.regex = {\n",
    "            'lower': re.compile(r'^([a-z]|_)*$'),\n",
    "            'lower_colon': re.compile(r'^([a-z]|_)*:([a-z]|_)*$'),\n",
    "            'problemchars': re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "        }\n",
    "        self.xml_reader = xml_reader\n",
    "\n",
    "    def key_type(self, element, keys):\n",
    "        if element.tag == \"tag\":\n",
    "            if self.regex['lower_colon'].search(element.attrib['k']):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif self.regex['problemchars'].search(element.attrib['k']):\n",
    "                keys['problemchars'] += 1\n",
    "            elif self.regex['lower'].search(element.attrib['k']):\n",
    "                keys['lower'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "        return keys\n",
    "\n",
    "    def test(self, filter_tag=None, limit=None):\n",
    "        keys = defaultdict(int)\n",
    "        for element in self.xml_reader.iterate(filter_tag=filter_tag, limit=limit):\n",
    "            keys = self.key_type(element, keys)\n",
    "        return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 943386, 'lower_colon': 777494, 'other': 5556}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "key_auditor = KeyAuditor(data)\n",
    "display(dict(key_auditor.test(filter_tag='tag')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if 'uid' in element.attrib:\n",
    "            users.add(element.attrib['uid'])\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def test3():\n",
    "\n",
    "    users = process_map(DATA_FILE)\n",
    "    display(len(users))\n",
    "    # assert len(users) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying street types is not as easy as doing it with English:\n",
    "* Street names don't include the word *Calle* explicitly, but avenues, boulevards, etc do. This means that any way not specifying the type on its name can be considered a normal street.\n",
    "* Some localities use number and/or names for streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "\n",
    "#street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "prefix_streets = ['[\\d]+', 'Sin', 'Ada', 'Alta', 'Ana', 'Blas', 'Bell', 'Cjal', 'Cmte', 'De', 'Del',\n",
    "                  'Cabo', 'Cap', 'Cnl', 'Tte', 'Carl', 'GRAL', 'GRL', 'Conc', 'Cruz', 'Cura',\n",
    "                  'Dip', 'Don', 'Diaz', 'Dirk', 'Eva', 'El', 'Ema', 'Emir', 'Emma', 'Enzo',\n",
    "                  'Ex', 'Fitz', 'Flor', 'John', 'Juez', 'La', 'Las', 'Leon', 'Los', 'Luis',\n",
    "                  'Lima', 'Lino', 'Lola', 'Lope', 'Mar', 'Olga', 'Olof', 'Paso', 'Paul', 'Pbro',\n",
    "                  'Palo', 'Paz', 'Pi', 'Pio', 'Plus', 'Raul', 'Rca', 'Rio', 'Rep', 'Ruiz',\n",
    "                  'Gdor', 'Gral', 'Grl', 'Igr', 'Ing', 'Jean', 'Juan', 'Hugo', 'Dr', 'Dr',\n",
    "                  'Ivan', 'Jose', 'Fray', 'Mons', 'San', 'Pte', 'Pres', 'Tcnl', 'Ruy', 'Sgt',\n",
    "                  'Sadi', 'Sir', 'Sor', 'Sta', 'Tgrl', 'Tuyu', 'Tres', 'Tula', 'Veva', 'Vito', 'Von']\n",
    "\n",
    "regex_str = r'^\\b(?!(%s))[a-zA-Z]{2,4}\\.?\\s' % '|'.join(prefix_streets)\n",
    "print('street_type_re:', regex_str)\n",
    "street_type_re = re.compile(regex_str, re.IGNORECASE)\n",
    "regex_str = r'^(%s)(?!\\s\\-\\s)[\\w\\s]+$' % '|'.join(prefix_streets)\n",
    "print('normal_street_names_re:', regex_str)\n",
    "normal_street_names_re = re.compile(regex_str, re.IGNORECASE)\n",
    "street_number_then_name_re = re.compile(r'^[\\d]+(\\s\\-\\s)[\\w\\s]+$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Calle\", \"Avenida\", \"Boulevard\", \"Pasaje\", \"Camino\", \"Diagonal\", \"Ruta Nacional\", \"Ruta Provincial\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"Av. \": \"Avenida\",\n",
    "            \"Ave. \": \"Avenida\",\n",
    "            \"Av \": \"Avenida\",\n",
    "            \"AV \": \"Avenida\",\n",
    "            \"av \": \"Avenida\",\n",
    "            \"Au \": \"Autopista\",\n",
    "            \"Avda \": \"Avenida\",\n",
    "            \"Avda. \": \"Avenida\",\n",
    "            \"BV \": \"Boulevard\",\n",
    "            \"PJE \": \"Pasaje\",\n",
    "            \"Pje. \": \"Pasaje\",\n",
    "            \"Cno \": \"Camino\",\n",
    "            \"Cno. \": \"Camino\",\n",
    "            \"Cmno \": \"Camino\",\n",
    "            \"Cno. \": \"Camino\",\n",
    "            \"Diag \": \"Diagonal\",\n",
    "            \"Diag. \": \"Diagonal\",\n",
    "            \"RN \": \"Ruta Nacional\",\n",
    "            \"RP \": \"Ruta Provincial\"\n",
    "          }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    \"\"\"\n",
    "    Types of names of streets:\n",
    "    - only numbers\n",
    "    - name of a person\n",
    "    - number - name\n",
    "    \"\"\"\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:  # street type identified\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "    elif normal_street_names_re.search(street_name):\n",
    "        street_types['Calle'].add(street_name)\n",
    "    elif street_number_then_name_re.search(street_name):\n",
    "        street_without_number = re.sub(r'^([\\d]+)\\s\\-\\s', '', street_name)\n",
    "        m = street_type_re.search(street_without_number)\n",
    "        if m:\n",
    "            street_type = m.group()\n",
    "            if street_type not in expected:\n",
    "                street_types[street_type].add(street_name)\n",
    "        else:\n",
    "            street_types['Calle'].add(street_name)\n",
    "    \n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for k in mapping:\n",
    "        if re.search(k, name, re.IGNORECASE) and re.search(mapping[k], name) is None:\n",
    "            name = re.sub(k, mapping[k]+' ', name, re.IGNORECASE)\n",
    "    return name\n",
    "\n",
    "\n",
    "def test4():\n",
    "    st_types = audit(DATA_FILE)\n",
    "    # assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types).keys())\n",
    "\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            if better_name != name:\n",
    "                print(name, \"=>\", better_name)\n",
    "            # if name == \"West Lexington St.\":\n",
    "            #     assert better_name == \"West Lexington Street\"\n",
    "            # if name == \"Baldwin Rd.\":\n",
    "            #     assert better_name == \"Baldwin Road\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test4()\n",
    "# Hosting | Webdesign | Translations => Hosting | Webdesign | Translations\n",
    "# 476 e/ 10 y 11 => 476 e/ 10 y 11\n",
    "# 7 bis e/ 474 y 475 => 7 bis e/ 474 y 475\n",
    "# Las Heras;Maipú => Las Heras;Maipú\n",
    "# Diagonal 74 № 996 Diagonal 74 y 5\n",
    "# Calle 411A\n",
    "# Teniente 1° Oscar Camilli\n",
    "# Avenida Calchaquí Esq. Av. 12 de Octubre\n",
    "# Colectora RP36\n",
    "# Paraguay 557\n",
    "# 101 - Avenida Sadi Carnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to wrangle the data and transform the shape of the data\n",
    "into the model we mentioned earlier. The output should be a list of dictionaries\n",
    "that look like this:\n",
    "\n",
    "{\n",
    "\"id\": \"2406124091\",\n",
    "\"type: \"node\",\n",
    "\"visible\":\"true\",\n",
    "\"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "\"pos\": [41.9757030, -87.6921867],\n",
    "\"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "\"amenity\": \"restaurant\",\n",
    "\"cuisine\": \"mexican\",\n",
    "\"name\": \"La Cabana De Don Luis\",\n",
    "\"phone\": \"1 (773)-271-5176\"\n",
    "}\n",
    "\n",
    "You have to complete the function 'shape_element'.\n",
    "We have provided a function that will parse the map file, and call the function with the element\n",
    "as an argument. You should return a dictionary, containing the shaped data for that element.\n",
    "We have also provided a way to save the data in a file, so that you could use\n",
    "mongoimport later on to import the shaped data into MongoDB. \n",
    "\n",
    "Note that in this exercise we do not use the 'update street name' procedures\n",
    "you worked on in the previous exercise. If you are using this code in your final\n",
    "project, you are strongly encouraged to use the code from previous exercise to \n",
    "update the street names before you save them to JSON. \n",
    "\n",
    "In particular the following things should be done:\n",
    "- you should process only 2 types of top level tags: \"node\" and \"way\"\n",
    "- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "    - attributes in the CREATED array should be added under a key \"created\"\n",
    "    - attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings. \n",
    "- if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "- if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "- if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n",
    "  process it in a way that you feel is best. For example, you might split it into a two-level\n",
    "  dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.\n",
    "- if there is a second \":\" that separates the type/direction of a street,\n",
    "  the tag should be ignored, for example:\n",
    "\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "\n",
    "  should be turned into:\n",
    "\n",
    "{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}\n",
    "\n",
    "- for \"way\" specifically:\n",
    "\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "\n",
    "should be turned into\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        node['type'] = element.tag\n",
    "        for a in element.attrib:\n",
    "            #print('iterating node/way:', tag, tag.attrib)\n",
    "            if a in CREATED:\n",
    "                if 'created' not in node:\n",
    "                    node['created'] = {}\n",
    "                node['created'][a] = element.attrib[a]\n",
    "            elif a in ('lat','lon'):\n",
    "                if 'pos' not in node:\n",
    "                    node['pos'] = [0,0]\n",
    "                key = 0 if a == 'lat' else 1\n",
    "                node['pos'][key] = float(element.attrib[a])\n",
    "            else:\n",
    "                node[a] = element.attrib[a]\n",
    "        for t in element.iter('tag'):\n",
    "            if problemchars.search(t.attrib['k']):\n",
    "                continue\n",
    "            elif t.attrib['k'].startswith('addr:'):\n",
    "                if 'address' not in node:\n",
    "                    node['address'] = {}\n",
    "                if t.attrib['k'].count(':') == 1:\n",
    "                    addr_type = t.attrib['k'].split(':')[1]\n",
    "                    node['address'][addr_type] = t.attrib['v']\n",
    "            elif t.attrib['k'].count(':') == 1:\n",
    "                extra_node = t.attrib['k'].split(':')\n",
    "                if extra_node[0] not in node:\n",
    "                    node[extra_node[0]] = {}\n",
    "                node[extra_node[0]][extra_node[1]] = t.attrib['v']\n",
    "        if element.tag == 'way':\n",
    "            for t in element.iter('nd'):\n",
    "                if 'node_refs' not in node:\n",
    "                    node['node_refs'] = []\n",
    "                if 'ref' in t.attrib:\n",
    "                    node['node_refs'].append(t.attrib['ref'])\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "def test5():\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map(DATA_FILE, True)\n",
    "    pprint.pprint(data[-1])\n",
    "    \n",
    "    \"\"\"correct_first_elem = {\n",
    "        \"id\": \"261114295\", \n",
    "        \"visible\": \"true\", \n",
    "        \"type\": \"node\", \n",
    "        \"pos\": [41.9730791, -87.6866303], \n",
    "        \"created\": {\n",
    "            \"changeset\": \"11129782\", \n",
    "            \"user\": \"bbmiller\", \n",
    "            \"version\": \"7\", \n",
    "            \"uid\": \"451048\", \n",
    "            \"timestamp\": \"2012-03-28T18:31:23Z\"\n",
    "        }\n",
    "    }\n",
    "    assert data[0] == correct_first_elem\n",
    "    assert data[-1][\"address\"] == {\n",
    "                                    \"street\": \"West Lexington St.\", \n",
    "                                    \"housenumber\": \"1412\"\n",
    "                                      }\n",
    "    assert data[-1][\"node_refs\"] == [ \"2199822281\", \"2199822390\",  \"2199822392\", \"2199822369\", \n",
    "                                    \"2199822370\", \"2199822284\", \"2199822281\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
